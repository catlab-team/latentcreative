<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Exploring Latent Dimensions of Crowd-sourced Creativity">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Exploring Latent Dimensions of Crowd-sourced Creativity</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');



  </script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://catlab-team.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Exploring Latent Dimensions of Crowd-sourced Creativity</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Umut Kocasarı</a>,</span>
            <span class="author-block">
              <a href="">Alperen Bağ</a>,</span>
            <span class="author-block">
              <a href="">Efehan Atıcı</a>,
            </span>
            <span class="author-block">
              <a href="">Pınar Yanardağ</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"> Bogazici University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://neuripscreativityworkshop.github.io/2021/accepted/ncw_88.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2112.06978"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=zXGeyELnhxo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/catlab-team/latentcreative"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recently, the discovery of interpretable directions in the latent spaces of pre-trained
            GANs has become a popular topic. While existing works mostly consider directions
            for semantic image manipulations, we focus on an abstract property: creativity.
            Can we manipulate an image to be more or less creative? We build our work
            on the largest AI-based creativity platform, Artbreeder, where users can generate
            images using pre-trained GAN models. We explore the latent dimensions of
            images generated on this platform and present a novel framework for manipulating
            images to make them more creative. Our code and dataset are available in <a href="http://github.com/catlab-team/latentcreative">this repository</a>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!--/ Introduction -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Introduction</h2>
          <p>
          One of the most popular platforms that collaboratively take advantage of generative adversarial
          networks is Artbreeder. Artbreeder helps users create new images using a BigGAN model,
          where users can adjust parameters or mix different images to generate new ones. Artbreeder platform
          is investigated by several recent work. In this study, we explore the manipulation of
          the latent space for creativity using a large dataset from the Artbreeder platform. We use this data
          as a proxy to build an assessor model that indicates the extent of creativity for a given image. Our
          approach modifies the image semantics by shifting the latent code towards creativity by a certain
          amount to make it more or less creative.
        </p>
      </div>
    </div>
    <!--/ Introduction -->

    <!--/ Methodology -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Methodology</h2>
          <p>
            In this paper, we use a pre-trained BigGAN model to manipulate images towards creativity
            and build our work on the GANalyze model. Given a generator G, a class vector y, a
            noise vector z, and an assessor function A, the GANalyze model solves the following problem:
            $$\mathcal{L}(\theta) = \mathbb{E}_{\mathbf{z},\mathbf{y},\alpha} [ A(G(T_{\theta}(\mathbf{z}, \alpha), \mathbf{y})) - (A(G(\mathbf{z}, \mathbf{y})) + \alpha))^2 ] $$
            where α is a scalar value representing
            the degree of manipulation, θ is the desired direction, and T is the transformation function defined as
            $$ T_\theta (\mathbf{z},\alpha) = \mathbf{z} + \alpha\theta $$ that moves the input z along the direction θ. In this work, we extend the GANalyze
            framework where we use a neural network that uses noise drawn from a distribution N (0; 1) which
            learns to map an input to different but functionally related (e.g., more creative) outputs:
            $$ \mathcal{L}(\theta) = \mathbb{E}_{\mathbf{z},\mathbf{y},\alpha} [ (A(G(F_{z}(\mathbf{z}, \alpha), F_{y}(\mathbf{y}, \alpha))))  -  (A(G(\mathbf{z}, \mathbf{y})) + \alpha))^2 ]   $$
            where the first term represents the score of the modified image after applying the function F with
            parameters z, y, and α, and the second term simply represents the score of the original image increased
            or decreased by α. F<sub>z</sub> computes a diverse direction θ with a noise ϵ as $$ F_{z}(\mathbf{z}, \alpha) = \mathbf{z} + \alpha \cdot \mathbf{NN}(\mathbf{z}, \epsilon) $$
            Moreover, we also learn a direction for class vectors as follows:
            $$  \mathcal{L}(\theta) = \mathbb{E}_{\mathbf{z},\mathbf{y},\alpha} [ A(G(F_{z}(\mathbf{z}, \alpha), F_{y}(\mathbf{y}, \alpha)))  -  (A(G(\mathbf{z}, \mathbf{y})) + \alpha))^2 ]  $$
            where F<sub>y</sub> is calculated using a 2-layer neural network (NN) as follows $$ F_{y}(\mathbf{y}, \alpha) = \mathbf{y} + \alpha \cdot \mathbf{NN}(\mathbf{y}, \epsilon) $$
        </p>
      </div>
    </div>
    <!--/ Methodology -->

    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>
          <p>
            We first investigate whether our model learns to navigate the latent space in such a way that it can
            increase or decrease creativity by a given α value. As can be seen from Figure 1 (a), our model
            achieves a much lower creativity score for low α values such as α = −0:5, while simultaneously
            achieving higher creativity for α = 0:4 and α = 0:5 compared to GANalyze. Next, we investigate what
            kind of image factors are changed to achieve these improvements.
          </p>
          <figure>
            <img src="static/images/plots.png" alt="Italian Trulli">
            <figcaption>Figure 1: Our method learns a better manipulation of the latent space compared to GANalyze.
              For each figure, the x-axis represents the α-value and the y-axis represents the mean.</figcaption>
              <br><br>
          </figure>
          <p>
            Following GANalyze, we examined
            redness, colorfulness, brightness, simplicity, squareness, centeredness and object size.
            We observe that both methods follow similar trends except colorfulness and object size.
            In particular, our method prefers to increase colorfulness and object size with increasing α values.
            Figure 2 shows some of the samples generated by our method and GANalyze.
            As can be seen from the visual results, our method is capable of performing several
            diverse manipulations on the input images.
          </p>
          <br>
          <p>
            <ul>
              <li><b>Redness:</b> is calculated as the normalized number of red pixels.</li>
              <li><b>Colorfulness:</b> is calculated by the metric from <a href="https://www.researchgate.net/publication/243135534_Measuring_Colourfulness_in_Natural_Images">this paper</a>.</li>
              <li><b>Brightness:</b> is calculated as the average pixel value after the grayscale transformation.</li>
              <li><b>Simplicity:</b> is computed as a histogram of pixel intensity used to measure entropy.</li>
              <li><b>Object Size:</b> Following GANalyze, we used Mask R-CNN to create a segmentation mask at the
                instance level of the generated image. For Object Size, we used the difference in the mask
                area when the α value increases or decreases.</li>
              <li><b>Centeredness:</b> is calculated as the deviation between the centroid of the mask from the
                center of the frame.</li>
              <li><b>Squareness:</b> is calculated as the ratio of the length of the minor and major axes of an ellipse
                with the same normalized central moments as the mask.</li>
            </ul>
          </p>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Some Outputs</h2>
        <figure>
          <img src="static/images/combined_cc_small.png" alt="Italian Trulli">
          <figcaption>Figure 2: Generated images created by our model and GANalyze</figcaption>
        </figure>
      </div>
    </div>
    <!--/ Results. -->

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Videos</h2>
        <center>
        <video width="640" height="640" controls>
          <source src="static/videos/video1.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>

        <center>
        <video width="640" height="640" controls>
          <source src="static/videos/video2.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>

        <center>
        <video width="640" height="640" controls>
          <source src="static/videos/video3.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>

        <center>
        <video width="640" height="640" controls>
          <source src="static/videos/video4.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>

        <center>
        <video width="640" height="640" controls>
          <source src="static/videos/video5.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>

        <center>
        <video width="640" height="640" controls>
          <source src="static/videos/video6.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>

        </center>
      </div>
    </div>

    <!-- Conclusion and Limitations -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Conclusion and Limitations</h2>
        <div class="content has-text-justified">
          <p>
            Our method is limited to manipulating GAN-generated images. As with any image synthesis tool,
            our method faces similar concerns and dangers of misuse if it can be applied to images of people or
            faces for malicious purposes, as described in <a href="https://arxiv.org/abs/1812.08685">this paper</a>. Our work also sheds light on the understanding of
            creativity and opens up possibilities to improve human-made art through GAN applications. On the
            other hand, we point out that using GAN-generated images as a proxy for creativity may bring its
            own limitations.
          </p>
        </div>
      </div>
    </div>
    <!--/ Conclusion and Limitations -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{latentcreative,
  author    = {Kocasari, Umut and Bag, Alperen and Atici, Efehan and Yanardag, Pinar},
  title     = {Exploring Latent Dimensions of Crowd-sourced Creativity},
  journal   = {NeurIPS 2021 Workshop on Machine Learning for Creativity and Design},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/nerfies/nerfies.github.io" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
  </div>
</footer>

</body>
</html>
